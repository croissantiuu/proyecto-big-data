{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sb\n",
    " \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"C:/Users/rodri/Documents/Python/Proyecto Integrador Big Data/data/TagsConseguidos/dataB_con_minutos_totales.csv\")\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1.groupby('In-Purchased').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1.groupby('Minutos jugadas Totales').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.factorplot('In-Purchased',data=data1,kind=\"count\", aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.factorplot('Minutos jugadas Totales',data=data1,kind=\"count\", aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot('Cantidad de descargas',data=data1.head(),kind=\"count\", aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de cadena a tipo entero\n",
    "data1['Cantidad de descargas'] = pd.to_numeric(data1['Cantidad de descargas'], errors='coerce').astype('Int64')\n",
    "data1['Cantidad de descargas'] = data1['Cantidad de descargas'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar los datos desde el CSV\n",
    "#data = pd.read_csv('tu_archivo.csv')\n",
    "\n",
    "# Seleccionar las columnas de interés\n",
    "X = data1[['Cantidad de descargas','Minutos jugadas Totales','Dias_Pasados','Precio']]\n",
    "y = data1['In-Purchased']  # Supongamos que 'Target' es la columna que representa la variable objetivo\n",
    "\n",
    "# 2. Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Escalar las características (opcional pero recomendado)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Inicializar los modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# 5. Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# 6. Mostrar los resultados\n",
    "for name, accuracy in results.items():\n",
    "    print(f'{name}: Accuracy = {accuracy}')\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Cantidad de descargas','Minutos jugadas Totales','Dias_Pasados','Precio']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para evaluar los modelos usando validación cruzada\n",
    "def evaluar_modelo(modelo, X, y):\n",
    "    scores = cross_val_score(modelo, X, y, cv=5)\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "# Comparar los modelos\n",
    "resultados = {}\n",
    "for nombre, modelo in models.items():\n",
    "    media, desviacion = evaluar_modelo(modelo, X, y)\n",
    "    resultados[nombre] = (media, desviacion)\n",
    "\n",
    "mejor_modelo = max(resultados, key=lambda k: resultados[k][0])\n",
    "print(\"El mejor modelo es:\", mejor_modelo)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for nombre, (media, desviacion) in resultados.items():\n",
    "    print(f\"{nombre}: Accuracy medio = {media}, Desviación estándar = {desviacion}\")\n",
    "\n",
    "# Interpretar los resultados\n",
    "# Analiza los resultados y toma una decisión sobre qué modelo es el mejor en función de las métricas y tus objetivos específicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que y_true son las etiquetas verdaderas y y_pred son las predicciones del modelo\n",
    "# Calculamos la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Graficamos la matriz de confusión\n",
    "plt.figure()\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.show()\n",
    "\n",
    "# Calculamos la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Graficamos la curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.show()\n",
    "\n",
    "# Calculamos la curva de precisión-recuperación\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Graficamos la curva de precisión-recuperación\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2)\n",
    "plt.xlabel('Recuperación')\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Curva de Precisión-Recuperación')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Cantidad de descargas','Minutos jugadas Totales','Dias_Pasados']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Cantidad de descargas','Minutos jugadas Totales','Precio','Multiplayer']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Cantidad de descargas','Dias_Pasados','Precio']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Minutos jugadas Totales','Dias_Pasados','Precio']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI MFS\n",
    "#\n",
    "#HERE MFS\n",
    "# Seleccionar las características (variables independientes) y la etiqueta (variable dependiente)\n",
    "X = data1[['Dias_Pasados']]\n",
    "y = data1['In-Purchased'] \n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar los modelos\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Entrenar los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño de los modelos\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Logistic Regression: Accuracy =\", accuracy_log_reg)\n",
    "print(\"Decision Tree: Accuracy =\", accuracy_decision_tree)\n",
    "print(\"Random Forest: Accuracy =\", accuracy_random_forest)\n",
    "print(\"SVM: Accuracy =\", accuracy_svm)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# y_true son los valores reales y y_pred son las predicciones del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse1 = mean_squared_error(accuracy_log_reg, y_pred)\n",
    "mse2 = mean_squared_error(accuracy_decision_tree, y_pred)\n",
    "mse3 = mean_squared_error(accuracy_random_forest, y_pred)\n",
    "mse4 = mean_squared_error(accuracy_svm, y_pred)\n",
    "\n",
    "print(\"Error cuadrático medio (MSE):\", mse)\n",
    "print(\"Error cuadrático medio (MSE):\", mse1)\n",
    "print(\"Error cuadrático medio (MSE):\", mse2)\n",
    "print(\"Error cuadrático medio (MSE):\", mse3)\n",
    "print(\"Error cuadrático medio (MSE):\", mse4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
